{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "I have broken down the 2018 New York parking ticket data so that more insite can be analyized\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, lit, concat\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "I plan on warehousing New Yorks parking ticket dataset inorder to find more insite on the trends that are happening when parking officers are handing out tickets. I'm using the New York City Parking Violation data and parking code data to add more insite to the main dataset for fiscial year 2018. My end solution will be a datalake with Dim tables Registration, Vehicle, Violation Location, and Violation Details. My Fact table will be the Ticket table. I used Spark and AWS S3 to create a datalake. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. \n",
    "\n",
    "- The first datset that I am using is City of New York parking voilation tickets that happend in 2018 which can be found at this link https://data.cityofnewyork.us/City-Government/Parking-Violations-Issued-Fiscal-Year-2018/faiq-9dfq.\n",
    "\n",
    "The information included in the dataset includes:\n",
    "\n",
    "Summons Number\n",
    "Plate ID\n",
    "Registration State\n",
    "Plate Type\n",
    "Issue Date\n",
    "Violation Code\n",
    "Vehicle Body Type\n",
    "Issuing Agency\n",
    "Street Code1\n",
    "Street Code2\n",
    "Street Code3\n",
    "Vehicle Expiration Date\n",
    "Violation Location\n",
    "Violation Precinct\n",
    "Issuer Precinct\n",
    "Issuer Code\n",
    "Issuer Command\n",
    "Issuer Squad\n",
    "Violation Time\n",
    "Time First Observed\n",
    "Violation County\n",
    "Violation In Front Of Or Opposite\n",
    "House Number\n",
    "Street Name\n",
    "Intersecting Street\n",
    "Date First Observed\n",
    "Law Section\n",
    "Sub Division\n",
    "Violation Legal Code\n",
    "Days Parking In Effect\n",
    "From Hours In Effect\n",
    "To Hours In Effect\n",
    "Vehicle Color\n",
    "Unregistered Vehicle?\n",
    "Vehicle Year\n",
    "Meter Number\n",
    "Feet From Curb\n",
    "Violation Post Code\n",
    "Violation Description\n",
    "No Standing or Stopping Violation\n",
    "Hydrant Violation\n",
    "\n",
    "\n",
    "Where did it come from? What type of information is included? \n",
    "\n",
    "- The second datset that I am using is the parking code discription which can be found at this link https://catalog.data.gov/dataset/dof-parking-violation-codes-63051.\n",
    "\n",
    "The information included in the dataset includes:\n",
    "\n",
    "Code\n",
    "Discription\n",
    "Manhattan 96th street & below\n",
    "All other areas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Capstone Cluster\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This fist dataset is the main dataset that has 4001111 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "df_ticket = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"parking-violations-issued-fiscal-year-2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4001111"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ticket.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summons Number</th>\n",
       "      <th>Plate ID</th>\n",
       "      <th>Registration State</th>\n",
       "      <th>Plate Type</th>\n",
       "      <th>Issue Date</th>\n",
       "      <th>Violation Code</th>\n",
       "      <th>Vehicle Body Type</th>\n",
       "      <th>Vehicle Make</th>\n",
       "      <th>Issuing Agency</th>\n",
       "      <th>Street Code1</th>\n",
       "      <th>Street Code2</th>\n",
       "      <th>Street Code3</th>\n",
       "      <th>Vehicle Expiration Date</th>\n",
       "      <th>Violation Location</th>\n",
       "      <th>Violation Precinct</th>\n",
       "      <th>Issuer Precinct</th>\n",
       "      <th>Issuer Code</th>\n",
       "      <th>Issuer Command</th>\n",
       "      <th>Issuer Squad</th>\n",
       "      <th>Violation Time</th>\n",
       "      <th>Time First Observed</th>\n",
       "      <th>Violation County</th>\n",
       "      <th>Violation In Front Of Or Opposite</th>\n",
       "      <th>House Number</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Intersecting Street</th>\n",
       "      <th>Date First Observed</th>\n",
       "      <th>Law Section</th>\n",
       "      <th>Sub Division</th>\n",
       "      <th>Violation Legal Code</th>\n",
       "      <th>Days Parking In Effect</th>\n",
       "      <th>From Hours In Effect</th>\n",
       "      <th>To Hours In Effect</th>\n",
       "      <th>Vehicle Color</th>\n",
       "      <th>Unregistered Vehicle?</th>\n",
       "      <th>Vehicle Year</th>\n",
       "      <th>Meter Number</th>\n",
       "      <th>Feet From Curb</th>\n",
       "      <th>Violation Post Code</th>\n",
       "      <th>Violation Description</th>\n",
       "      <th>No Standing or Stopping Violation</th>\n",
       "      <th>Hydrant Violation</th>\n",
       "      <th>Double Parking Violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1105232165</td>\n",
       "      <td>GLS6001</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>2018-07-03T00:00:00.000</td>\n",
       "      <td>14</td>\n",
       "      <td>SDN</td>\n",
       "      <td>HONDA</td>\n",
       "      <td>X</td>\n",
       "      <td>47130</td>\n",
       "      <td>13230</td>\n",
       "      <td>80030</td>\n",
       "      <td>20180702</td>\n",
       "      <td>0078</td>\n",
       "      <td>78</td>\n",
       "      <td>968</td>\n",
       "      <td>86684</td>\n",
       "      <td>0968</td>\n",
       "      <td>0000</td>\n",
       "      <td>0811P</td>\n",
       "      <td>None</td>\n",
       "      <td>K</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>HANSON PLACE</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "      <td>D1</td>\n",
       "      <td>None</td>\n",
       "      <td>BBYBBBB</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1121274900</td>\n",
       "      <td>HXM7361</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>2018-06-28T00:00:00.000</td>\n",
       "      <td>46</td>\n",
       "      <td>SDN</td>\n",
       "      <td>NISSA</td>\n",
       "      <td>X</td>\n",
       "      <td>28990</td>\n",
       "      <td>14890</td>\n",
       "      <td>15040</td>\n",
       "      <td>20200203</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>968</td>\n",
       "      <td>103419</td>\n",
       "      <td>0968</td>\n",
       "      <td>0000</td>\n",
       "      <td>1145A</td>\n",
       "      <td>None</td>\n",
       "      <td>Q</td>\n",
       "      <td>F</td>\n",
       "      <td>71-30</td>\n",
       "      <td>AUSTIN ST</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>BBBBBBB</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>GRY</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1130964875</td>\n",
       "      <td>GTR7949</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>2018-06-08T00:00:00.000</td>\n",
       "      <td>24</td>\n",
       "      <td>SUBN</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>X</td>\n",
       "      <td>64</td>\n",
       "      <td>18510</td>\n",
       "      <td>99</td>\n",
       "      <td>20180930</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>835</td>\n",
       "      <td>0</td>\n",
       "      <td>0835</td>\n",
       "      <td>0000</td>\n",
       "      <td>0355P</td>\n",
       "      <td>None</td>\n",
       "      <td>R</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>GREAT KILLS BOAT LAU</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "      <td>D5</td>\n",
       "      <td>None</td>\n",
       "      <td>BBBBBBB</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1130964887</td>\n",
       "      <td>HH1842</td>\n",
       "      <td>NC</td>\n",
       "      <td>PAS</td>\n",
       "      <td>2018-06-07T00:00:00.000</td>\n",
       "      <td>24</td>\n",
       "      <td>P-U</td>\n",
       "      <td>FORD</td>\n",
       "      <td>X</td>\n",
       "      <td>11310</td>\n",
       "      <td>39800</td>\n",
       "      <td>39735</td>\n",
       "      <td>0E-8</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>835</td>\n",
       "      <td>0</td>\n",
       "      <td>0835</td>\n",
       "      <td>0000</td>\n",
       "      <td>0123P</td>\n",
       "      <td>None</td>\n",
       "      <td>R</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>GREAT KILLS PARK BOA</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "      <td>D5</td>\n",
       "      <td>None</td>\n",
       "      <td>BBBBBBB</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1131599342</td>\n",
       "      <td>HDG7076</td>\n",
       "      <td>NY</td>\n",
       "      <td>PAS</td>\n",
       "      <td>2018-06-29T00:00:00.000</td>\n",
       "      <td>17</td>\n",
       "      <td>SUBN</td>\n",
       "      <td>HYUND</td>\n",
       "      <td>X</td>\n",
       "      <td>47130</td>\n",
       "      <td>13230</td>\n",
       "      <td>80030</td>\n",
       "      <td>20190124</td>\n",
       "      <td>0078</td>\n",
       "      <td>78</td>\n",
       "      <td>868</td>\n",
       "      <td>2354</td>\n",
       "      <td>0868</td>\n",
       "      <td>0000</td>\n",
       "      <td>0514P</td>\n",
       "      <td>None</td>\n",
       "      <td>K</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>HANSON PLACE</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "      <td>C4</td>\n",
       "      <td>None</td>\n",
       "      <td>BBBBBBB</td>\n",
       "      <td>ALL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Summons Number Plate ID Registration State Plate Type  \\\n",
       "0     1105232165  GLS6001                 NY        PAS   \n",
       "1     1121274900  HXM7361                 NY        PAS   \n",
       "2     1130964875  GTR7949                 NY        PAS   \n",
       "3     1130964887   HH1842                 NC        PAS   \n",
       "4     1131599342  HDG7076                 NY        PAS   \n",
       "\n",
       "                Issue Date Violation Code Vehicle Body Type Vehicle Make  \\\n",
       "0  2018-07-03T00:00:00.000             14               SDN        HONDA   \n",
       "1  2018-06-28T00:00:00.000             46               SDN        NISSA   \n",
       "2  2018-06-08T00:00:00.000             24              SUBN         JEEP   \n",
       "3  2018-06-07T00:00:00.000             24               P-U         FORD   \n",
       "4  2018-06-29T00:00:00.000             17              SUBN        HYUND   \n",
       "\n",
       "  Issuing Agency Street Code1 Street Code2 Street Code3  \\\n",
       "0              X        47130        13230        80030   \n",
       "1              X        28990        14890        15040   \n",
       "2              X           64        18510           99   \n",
       "3              X        11310        39800        39735   \n",
       "4              X        47130        13230        80030   \n",
       "\n",
       "  Vehicle Expiration Date Violation Location Violation Precinct  \\\n",
       "0                20180702               0078                 78   \n",
       "1                20200203                112                112   \n",
       "2                20180930                122                122   \n",
       "3                    0E-8                122                122   \n",
       "4                20190124               0078                 78   \n",
       "\n",
       "  Issuer Precinct Issuer Code Issuer Command Issuer Squad Violation Time  \\\n",
       "0             968       86684           0968         0000          0811P   \n",
       "1             968      103419           0968         0000          1145A   \n",
       "2             835           0           0835         0000          0355P   \n",
       "3             835           0           0835         0000          0123P   \n",
       "4             868        2354           0868         0000          0514P   \n",
       "\n",
       "  Time First Observed Violation County Violation In Front Of Or Opposite  \\\n",
       "0                None                K                                 F   \n",
       "1                None                Q                                 F   \n",
       "2                None                R                              None   \n",
       "3                None                R                              None   \n",
       "4                None                K                                 F   \n",
       "\n",
       "  House Number           Street Name Intersecting Street Date First Observed  \\\n",
       "0            2          HANSON PLACE                None                   0   \n",
       "1        71-30             AUSTIN ST                None                   0   \n",
       "2         None  GREAT KILLS BOAT LAU                None                   0   \n",
       "3         None  GREAT KILLS PARK BOA                None                   0   \n",
       "4            2          HANSON PLACE                None                   0   \n",
       "\n",
       "  Law Section Sub Division Violation Legal Code Days Parking In Effect      \\\n",
       "0         408           D1                 None                    BBYBBBB   \n",
       "1         408            C                 None                    BBBBBBB   \n",
       "2         408           D5                 None                    BBBBBBB   \n",
       "3         408           D5                 None                    BBBBBBB   \n",
       "4         408           C4                 None                    BBBBBBB   \n",
       "\n",
       "  From Hours In Effect To Hours In Effect Vehicle Color Unregistered Vehicle?  \\\n",
       "0                  ALL                ALL          BLUE                     0   \n",
       "1                  ALL                ALL           GRY                     0   \n",
       "2                  ALL                ALL         GREEN                     0   \n",
       "3                  ALL                ALL         WHITE                     0   \n",
       "4                  ALL                ALL         GREEN                     0   \n",
       "\n",
       "  Vehicle Year Meter Number Feet From Curb Violation Post Code  \\\n",
       "0         2006            -              0                None   \n",
       "1         2017            -              0                None   \n",
       "2            0            -              0                None   \n",
       "3            0            -              0                None   \n",
       "4         2007            -              0                None   \n",
       "\n",
       "  Violation Description No Standing or Stopping Violation Hydrant Violation  \\\n",
       "0                  None                              None              None   \n",
       "1                  None                              None              None   \n",
       "2                  None                              None              None   \n",
       "3                  None                              None              None   \n",
       "4                  None                              None              None   \n",
       "\n",
       "  Double Parking Violation  \n",
       "0                     None  \n",
       "1                     None  \n",
       "2                     None  \n",
       "3                     None  \n",
       "4                     None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ticket.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ticket_code = spark.read.json(\"parking_violation codes.json\", multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[row-vc2y~qug8_qh44, 00000000-0000-0000-CF04-...</td>\n",
       "      <td>((Department of Finance (DOF), http://www.nyc....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  [[row-vc2y~qug8_qh44, 00000000-0000-0000-CF04-...   \n",
       "\n",
       "                                                meta  \n",
       "0  ((Department of Finance (DOF), http://www.nyc....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ticket_code.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "In the main ticket file there were a lot of null values:\n",
    "\n",
    "- Violation Post Code\n",
    "- Violation Description\n",
    "- No Standing or Stopping Violation\n",
    "- Hydrant Violation\n",
    "\n",
    "It seemed that these values where not used. as for the rest of these data seemed fine in terms of completeness, but there were duplicates just due to the data not being normailzed.\n",
    "\n",
    "The second dataset has the parking codes that are complete, but I only needed the 'Code' and 'Definition' columns. The other columns didn't seem st match the data that I needed so I removed it.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Please see the following steps that I did to clean the Codes data. The main Ticket data did not really need any cleaning. most of the columns that had lots of nulls or data that wasn't I simply didn't select when creating the tables. Basiclly, I dropped those columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the Code and Definition data from the JSON payload and put them in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = []\n",
    "definition_list = []\n",
    "for data in df_ticket_code.toPandas().data[0]:\n",
    "    code_list.append(data[8])\n",
    "    definition_list.append(data[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a dataframe with columns Code and Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes = pd.DataFrame(columns=['Code','Definition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Put the lists into the previouly created dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes['Code'] = code_list\n",
    "df_codes['Definition'] = definition_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cast the Pandas Dataframe to a Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_spark  = spark.createDataFrame(df_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>NO STOP/STANDNG EXCEPT PAS P/U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>ANGLE PARKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>NO STANDING-TAXI STAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>REG STICKER-MUTILATED/C'FEIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>FAIL TO DSPLY MUNI METER RECPT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Code                      Definition\n",
       "0   30  NO STOP/STANDNG EXCEPT PAS P/U\n",
       "1   60                   ANGLE PARKING\n",
       "2   13          NO STANDING-TAXI STAND\n",
       "3   73    REG STICKER-MUTILATED/C'FEIT\n",
       "4   38  FAIL TO DSPLY MUNI METER RECPT"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_spark.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Please see the ERD PDF that I included.\n",
    "\n",
    "- I choose to make the Ticket Table the Fact Table because most of the data that it contains are time stamps and id that are linked to all the other discriptive data that linkd the DIM tables.\n",
    "\n",
    "- The Vehicle table is the first DIM table I create. It's PK in the License plate number. I thought that it was the most appopreate for a unique indentifier for a car since the VIN number is not something that was included in the dataset. The other attributs are things that describe the car -- Color, Make, Body type ect...\n",
    "\n",
    "- The Registration table has the Plate ID as the PK. The other attibutes are things that describe a cars registration like if it has expired or what state the car has registraton in.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "- Select the Plate ID, Vehicle Make, Vehicle Body Type, Vehile Color and Vehicle Year from df_tick dataframe and assign to the df_vehicle_table\n",
    "- Select the Plate ID, Plate Type, Regestration State Vehicle Experation Date, Unregestration Expired Date and assign to the df_registration_table.\n",
    "- Select the Street Code1, Street Code3, Street Code3, Violation Precinct, Violation County, House Number, Street Name, Days Parking in Effect, From Hours In Effect, and To Hours In Effect and assign to df_violation_location_table.\n",
    "- Select df_violation_location_table and concatonate the street_code1, street_code2, and street_code3 to make a primary key.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vehicle Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vehicle_table = df_ticket.select(col('Plate ID').alias('plate_id'), col('Vehicle Make').alias('vehicle_make')\\\n",
    "                                    ,col('Vehicle Body Type').alias('vehicle_body_type'), col('Vehicle Color').alias('vehicle_color')\\\n",
    "                                    ,col('Vehicle Year').alias('vehicle_year'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create registration table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_registration_table = df_ticket.select(col('Plate ID').alias('plate_id'), col('Plate Type').alias('plate_type')\\\n",
    "                                         ,col('Registration State').alias('registration_state'), col('Vehicle Expiration Date').alias('registration_expired_date')\\\n",
    "                                        ,col('Unregistered Vehicle?').alias('unregistered_vehicle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Violation Location Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_violation_location_table = df_ticket.select(col('Street Code1').alias('street_code1'), col('Street Code2').alias('street_code2')\\\n",
    "                                         ,col('Street Code3').alias('street_code3'), col('Violation Precinct').alias('violation_precinct')\\\n",
    "                                        ,col('Violation County').alias('violation_county'),col('House Number').alias('house_number')\n",
    "                                        ,col('Street Name').alias('street_name'),col('Days Parking In Effect    ').alias('parking_enforced_days')\n",
    "                                        ,col('From Hours In Effect').alias('from_enforced_hours'),col('To Hours In Effect').alias('to_enforced_hours'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_violation_location_table = df_violation_location_table.withColumn(\"street_code_key\", \\\n",
    "                                    concat(col(\"street_code1\"), lit('-'),col(\"street_code2\"), lit('-'),col(\"street_code3\"))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Codes table with main tables code details columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_joined_spark = df_codes_spark.join(df_ticket.select(col('Law Section'), col('Sub Division'), col('Violation Code'))).where(df_ticket['Violation Code'] == df_codes_spark['Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes_joined_spark1 = df_codes_joined_spark.select(col('Code').alias('code'), col('Definition').alias('definition'), col('Law Section').alias('law_section'), col('Sub Division').alias('sub_division')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "      <th>law_section</th>\n",
       "      <th>sub_division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>SIDEWALK</td>\n",
       "      <td>408</td>\n",
       "      <td>E5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>NO STANDING-HOTEL LOADING</td>\n",
       "      <td>408</td>\n",
       "      <td>C7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>FAIL TO DISP. MUNI METER RECPT</td>\n",
       "      <td>408</td>\n",
       "      <td>H1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>IDLING</td>\n",
       "      <td>408</td>\n",
       "      <td>J2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>DOUBLE PARKING-MIDTOWN COMML</td>\n",
       "      <td>408</td>\n",
       "      <td>L4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                      definition law_section sub_division\n",
       "0   51                        SIDEWALK         408           E5\n",
       "1   11       NO STANDING-HOTEL LOADING         408           C7\n",
       "2   69  FAIL TO DISP. MUNI METER RECPT         408           H1\n",
       "3    8                          IDLING         408           J2\n",
       "4   47    DOUBLE PARKING-MIDTOWN COMML         408           L4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_codes_joined_spark1.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Ticket Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_fact_df = df_ticket.join(df_violation_location_table).where((df_ticket['Street Code1'] == df_violation_location_table['street_code1']) & (df_ticket['Street Code2'] == df_violation_location_table['street_code2']) & (df_ticket['Street Code3'] == df_violation_location_table['street_code3'])).dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alias the Columns to snake case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_fact_df = ticket_fact_df.select(col('Summons Number').alias('summons_number'), col('Plate ID').alias('plate_id'), col('Issue Date').alias('issue_date'), col('Violation Code').alias('violation_code'), col('street_code_key')).limit(100).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "if ticket_fact_df.count() = 0:\n",
    "    print(\"error ticket_fact_df is empty\")\n",
    "\n",
    "if df_violation_location_table.count() = 0:\n",
    "    print(\"error ticket_fact_df is empty\")\n",
    "    \n",
    "if df_registration_table.count() = 0:\n",
    "    print(\"df_registration_table is empty\")\n",
    "    \n",
    "if df_codes_joined_spark.count() = 0:\n",
    "    print(\"df_codes_joined_spark is empty\")\n",
    "    \n",
    "if df_vehicle_table.count() = 0:\n",
    "    print(\"df_vehicle_table is empty\")\n",
    "    \n",
    "    \n",
    "if ticket_fact_df.count() > ticket_fact_df.dropDuplicates().count():\n",
    "    print(\"error ticket_fact_df has duplicates\")\n",
    "    \n",
    "if df_violation_location_table.count() > df_violation_location_table.dropDuplicates().count():\n",
    "    print(\"df_violation_location_table has duplicates\")\n",
    "    \n",
    "if df_registration_table.count() > df_registration_table.dropDuplicates().count():\n",
    "    print(\"df_registration_table has duplicates\")\n",
    "    \n",
    "if df_codes_joined_spark.count() > df_codes_joined_spark.dropDuplicates().count():\n",
    "    print(\"df_codes_joined_spark has duplicates\")\n",
    "    \n",
    "if df_vehicle_table.count() > df_vehicle_table.dropDuplicates().count():\n",
    "    print(\"df_vehicle_table has duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "\n",
    "- Please see the ERD I attached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I chose Spark because it is fast and can scale. For this project I was able to get up and running with little configureation. If I was using Redshift I would need to take into consideration of how many CPU's\\cores that I needed as my data scaled. Spark is also nice because it offers SQL type commands or Pandas commands, so it doesn't matter if you come from a SQL background or Pandas background, your going to be able to use the skills you are stronest with -- you can't do that with Redshift, Postgres, or Airflow. S3 is also great because I can control who has access to what datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This data only needs to be updated once a year because the govenment only publishes a new data set once a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the data was increased by 100 times I wouldn't do anything because if is the fastest option due to the data needing to be processed once a year in bulk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- if the data needed to be run on a daily basis at 7am I would have probably used AirFlow. The scheduling funtionality as well ad the DAG work flow would better accomidate the refresh of data as well as it there was an issue and the data needed to be back-filled. None of the other options have that kind of robust funationality that we have covered in this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- S3 is not really a datbase, but I would be able to add people to groups that only gave them access to buckets that they where assigned to. If I was to have a database that required a large amount of users, I would use Redshift because of the amount of computation power it has compaired to Postgres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
